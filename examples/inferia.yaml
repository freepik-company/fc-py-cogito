inferia:
  server:
    cache_dir: /tmp/inferia
    description: Inference server
    fastapi:
      access_log: true
      debug: false
      host: 127.0.0.1
      port: 8000
    name: Sapientia per Inferentiam
    route:
      args:
      - description: The prompt to generate text from
        name: prompt
        type: str
      description: Make a single prediction
      name: Predict
      path: /v1/predict
      predictor: predict:Predictor
      response:
        description: The generated text
        type: PredictResponse
      tags:
      - predict
      threads: 1
    version: 0.1.0
  training: {}
